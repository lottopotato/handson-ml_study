{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Ensemble Learning #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 voting-Classifier ##\n",
    "vote basis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr,', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)), ('rnd', R...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_moons(n_samples = 100, noise = 0.15)\n",
    "X_train, y_train = X[:80], y[:80]\n",
    "X_test, y_test = X[80:], y[80:]\n",
    "log_clf = LogisticRegression(solver = 'liblinear')\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 10)\n",
    "svm_clf = SVC(gamma='auto')\n",
    "\n",
    "\"\"\"\n",
    "    voting = hard or soft\n",
    "    hard is voting by majority\n",
    "    soft is voting by probability\n",
    "\"\"\"\n",
    "voting_clf = VotingClassifier(estimators = [('lr,', log_clf), ('rnd', rnd_clf), ('svm', svm_clf)],\n",
    "                             voting = 'hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9\n",
      "RandomForestClassifier 0.95\n",
      "SVC 0.95\n",
      "VotingClassifier 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7.2 Bagging, Pasting ##\n",
    "sampling from allow(Bagging) or not allow(Pasting) duplicates of subset of train-sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Bagging, Pasting with scikit-learn ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators = 500,\n",
    "    max_samples = 10, bootstrap=True, n_jobs = -1, oob_score=True) ## when use Pasting, bootstrap = False\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 oob score ###\n",
    "if use bagging, then sampling selected to approximity 63% on average <br>\n",
    "left sample is called **oob(out-of-bag)** <br>\n",
    "oob is difference by each model <br>\n",
    "so validation can use from oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10958904, 0.89041096],\n",
       "       [0.09633028, 0.90366972],\n",
       "       [0.88888889, 0.11111111],\n",
       "       [0.92448513, 0.07551487],\n",
       "       [0.84494382, 0.15505618],\n",
       "       [0.29357798, 0.70642202],\n",
       "       [0.75929978, 0.24070022],\n",
       "       [0.6712963 , 0.3287037 ],\n",
       "       [0.11590909, 0.88409091],\n",
       "       [0.23318386, 0.76681614],\n",
       "       [0.8280543 , 0.1719457 ],\n",
       "       [0.71493213, 0.28506787],\n",
       "       [0.88045977, 0.11954023],\n",
       "       [0.19506726, 0.80493274],\n",
       "       [0.96860987, 0.03139013],\n",
       "       [0.86261261, 0.13738739],\n",
       "       [0.9556541 , 0.0443459 ],\n",
       "       [0.94520548, 0.05479452],\n",
       "       [0.10250569, 0.89749431],\n",
       "       [0.44063927, 0.55936073],\n",
       "       [0.08539326, 0.91460674],\n",
       "       [0.88340807, 0.11659193],\n",
       "       [0.81455399, 0.18544601],\n",
       "       [0.80504587, 0.19495413],\n",
       "       [0.25950783, 0.74049217],\n",
       "       [0.0955711 , 0.9044289 ],\n",
       "       [0.08237986, 0.91762014],\n",
       "       [0.35280899, 0.64719101],\n",
       "       [0.07744875, 0.92255125],\n",
       "       [0.76091954, 0.23908046],\n",
       "       [0.13272311, 0.86727689],\n",
       "       [0.77161863, 0.22838137],\n",
       "       [0.10738255, 0.89261745],\n",
       "       [0.96213808, 0.03786192],\n",
       "       [0.29912664, 0.70087336],\n",
       "       [0.0520362 , 0.9479638 ],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.40774487, 0.59225513],\n",
       "       [0.76888889, 0.23111111],\n",
       "       [0.83820225, 0.16179775],\n",
       "       [0.66050808, 0.33949192],\n",
       "       [0.0979021 , 0.9020979 ],\n",
       "       [0.17342342, 0.82657658],\n",
       "       [0.93135011, 0.06864989],\n",
       "       [0.0520362 , 0.9479638 ],\n",
       "       [0.81818182, 0.18181818],\n",
       "       [0.84187082, 0.15812918],\n",
       "       [0.87695749, 0.12304251],\n",
       "       [0.36238532, 0.63761468],\n",
       "       [0.7862069 , 0.2137931 ],\n",
       "       [0.88089888, 0.11910112],\n",
       "       [0.1627907 , 0.8372093 ],\n",
       "       [0.08685969, 0.91314031],\n",
       "       [0.49082569, 0.50917431],\n",
       "       [0.82448037, 0.17551963],\n",
       "       [0.66297118, 0.33702882],\n",
       "       [0.28666667, 0.71333333],\n",
       "       [0.05263158, 0.94736842],\n",
       "       [0.90639269, 0.09360731],\n",
       "       [0.17931034, 0.82068966],\n",
       "       [0.09862385, 0.90137615],\n",
       "       [0.03644647, 0.96355353],\n",
       "       [0.35550459, 0.64449541],\n",
       "       [0.09619687, 0.90380313],\n",
       "       [0.07918552, 0.92081448],\n",
       "       [0.91533181, 0.08466819],\n",
       "       [0.84734513, 0.15265487],\n",
       "       [0.79772727, 0.20227273],\n",
       "       [0.09777778, 0.90222222],\n",
       "       [0.92938497, 0.07061503],\n",
       "       [0.13378685, 0.86621315],\n",
       "       [0.91116173, 0.08883827],\n",
       "       [0.8929385 , 0.1070615 ],\n",
       "       [0.93918919, 0.06081081],\n",
       "       [0.6826484 , 0.3173516 ],\n",
       "       [0.81179138, 0.18820862],\n",
       "       [0.76537585, 0.23462415],\n",
       "       [0.80278422, 0.19721578],\n",
       "       [0.10416667, 0.89583333],\n",
       "       [0.87954545, 0.12045455]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Random-patches and Random-subspaces ##\n",
    "(skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Random Forest ##\n",
    "ensemble of decision tree with bagging or pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes=16, n_jobs = -1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 Extremely-Randomized Trees(extra-Trees) ###\n",
    "(skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 feature importance ###\n",
    "random-forest merit is easy measurement to relative importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09887461691354178\n",
      "sepal width (cm) 0.02423765584889478\n",
      "petal length (cm) 0.43560665450378516\n",
      "petal width (cm) 0.4412810727337784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500, n_jobs = -1)\n",
    "rnd_clf.fit(iris['data'], iris['target'])\n",
    "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Boosting ##\n",
    "(skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Stacking ##\n",
    "(skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
